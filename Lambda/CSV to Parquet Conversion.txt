 import pandas as pd
import boto3
import urllib
import io

s3 = boto3.client('s3')
s3_resource = boto3.resource('s3')

def lambda_handler(event, context):
    
  #try:
        
   for record in event['Records']:
    
    # Retrieve the input file from the event object
    
    source_bucket = record['s3']['bucket']['name']
    source_key = urllib.parse.unquote_plus(record['s3']['object']['key'])
    
    # Set the S3 bucket where the output file will be stored
    
    output_bucket = 'csv-par-opt'
    
    # Set the name of the output file (with .parquet extension)
    
    output_file = 'Anything.parquet'
    
    # Read the CSV file from S3 into a Pandas DataFrame
    
    csv_object = s3.get_object(Bucket= source_bucket , Key= source_key)
    csv_body = csv_object['Body'].read().decode('utf-8')
    df = pd.read_csv(io.StringIO(csv_body))
    
    # Convert the DataFrame to Parquet format
    
    parquet_buffer = io.BytesIO()
    df.to_parquet(parquet_buffer)
    
    # Save the Parquet file to S3
    
    parquet_buffer.seek(0)
    s3_resource.Object(output_bucket, output_file).put(Body=parquet_buffer.getvalue())
    
    
  except TypeError :
     print("TypeError has occured ")
        
  except Exception :
     print("An Exception has occured ")
  
    